#### Figure 4 -- 8 x 4 gpus
# tinyllama 4,8,4 init, muon
python train.py --epochs=1 --max_length=1024 --out_path=huginn_llama --optim_config.lr=5e-5 --model_name="smcleish/Recurrent-TinyLlama-3T-untrained" --preprocessed_data_path="$PROCESSED_DATA_PATH/smcleish/Recurrent-TinyLlama-3T-untrained/tinyllama_1_1b_packed_350b_sample_wrapped_packing/dataset" --is_parquet_dataset=true --scheduler_args.cooldown=0.9 --scheduler_args.warmup=0.005 --max_grad_norm=1.0 --micro_batch_size=8 --batch_size=32 --no_amp=false --max_steps=25000 --compile=false --save_interval=1000 --save_n_mins_before_timeout=5 --mean_recurrence_schedule.turn_on=true --mean_recurrence_schedule.warmup=0.25 --muon.use_muon=true --muon.lr=0.001

# tinyllama 4,8,4 init, adamw
python train.py --epochs=1 --max_length=1024 --out_path=huginn_llama --optim_config.lr=5e-5 --model_name="smcleish/Recurrent-TinyLlama-3T-untrained" --preprocessed_data_path="$PROCESSED_DATA_PATH/smcleish/Recurrent-TinyLlama-3T-untrained/tinyllama_1_1b_packed_350b_sample_wrapped_packing/dataset" --is_parquet_dataset=true --scheduler_args.cooldown=0.9 --scheduler_args.warmup=0.0042 --max_grad_norm=1.0 --micro_batch_size=8 --batch_size=32 --no_amp=false --max_steps=30000 --compile=false --save_interval=1000 --save_n_mins_before_timeout=5 --mean_recurrence_schedule.turn_on=true --mean_recurrence_schedule.warmup=0.25

# tinyllama 4,8,4 init, ellisadam (adamw*)
python train.py --epochs=1 --max_length=1024 --out_path=huginn_llama --optim_config.lr=5e-5 --model_name="smcleish/Recurrent-TinyLlama-3T-untrained" --preprocessed_data_path="$PROCESSED_DATA_PATH/smcleish/Recurrent-TinyLlama-3T-untrained/tinyllama_1_1b_packed_350b_sample_wrapped_packing/dataset" --is_parquet_dataset=true --scheduler_args.cooldown=0.9 --scheduler_args.warmup=0.005 --max_grad_norm=1.0 --micro_batch_size=8 --batch_size=32 --no_amp=false --max_steps=25000 --compile=false --save_interval=1000 --save_n_mins_before_timeout=5 --mean_recurrence_schedule.turn_on=true --mean_recurrence_schedule.warmup=0.25 --use_ellis_adam.use_ellis_adam=true

#### Figure 5/7 -- 16 x 4 gpus
# tinyllama 4,8,4 init, `mean_recurrence_schedule.max_mean_rec=YOUR_MAX_MEAN`
python train.py --epochs=1 --max_length=1024 --out_path=huginn_llama --optim_config.lr=5e-5 --model_name="smcleish/Recurrent-TinyLlama-3T-untrained" --preprocessed_data_path="$PROCESSED_DATA_PATH/smcleish/Recurrent-TinyLlama-3T-untrained/tinyllama_1_1b_packed_nemotron_cc_math_v1_4plus_wrapped_packing/dataset" --is_parquet_dataset=true --scheduler_args.cooldown=0.6 --scheduler_args.warmup=0.0025 --max_grad_norm=1.0 --micro_batch_size=8 --batch_size=16 --no_amp=false --max_steps=50000 --compile=false --save_interval=1000 --save_n_mins_before_timeout=5 --mean_recurrence_schedule.turn_on=true --mean_recurrence_schedule.warmup=0.75  --mean_recurrence_schedule.warmup_type="1-sqrt" --mean_recurrence_schedule.max_mean_rec=4 --muon.use_muon=true --muon.lr=0.001

# tinyllama non-recurrent
python train.py --epochs=1 --max_length=1024 --out_path=huginn_llama --optim_config.lr=5e-5 --model_name="TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T" --preprocessed_data_path="$PROCESSED_DATA_PATH/smcleish/Recurrent-TinyLlama-3T-untrained/tinyllama_1_1b_packed_nemotron_cc_math_v1_4plus_wrapped_packing/dataset" --is_parquet_dataset=true --scheduler_args.cooldown=0.6 --scheduler_args.warmup=0.0025 --max_grad_norm=1.0 --micro_batch_size=8 --batch_size=16 --no_amp=false --max_steps=50000 --compile=false --non_recurrent_model=true --save_interval=1000 --save_n_mins_before_timeout=5 --muon.use_muon=true --muon.lr=0.001

#### Figure 8 -- 8 x 4 gpus
##Â single phase
# tinyllama non-recurrent
python train.py --epochs=1 --max_length=1024 --out_path=huginn_llama --optim_config.lr=5e-5 --model_name="TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T" --preprocessed_data_path="$PROCESSED_DATA_PATH/smcleish/Recurrent-TinyLlama-3T-untrained/fineweb_nemotron_sft_general_math_even_mix/dataset" --is_parquet_dataset=true --scheduler_args.cooldown=0.9 --scheduler_args.warmup=0.005 --max_grad_norm=1.0 --micro_batch_size=8 --batch_size=32 --no_amp=false --max_steps=25000 --compile=false --non_recurrent_model=true --save_interval=1000 --save_n_mins_before_timeout=5 --muon.use_muon=true --muon.lr=0.001

# tinyllama 4,8,4 init
python train.py --epochs=1 --max_length=1024 --out_path=huginn_llama --optim_config.lr=5e-5 --model_name="smcleish/Recurrent-TinyLlama-3T-untrained" --preprocessed_data_path="$PROCESSED_DATA_PATH/smcleish/Recurrent-TinyLlama-3T-untrained/fineweb_nemotron_sft_general_math_even_mix/dataset" --is_parquet_dataset=true --scheduler_args.cooldown=0.9 --scheduler_args.warmup=0.005 --max_grad_norm=1.0 --micro_batch_size=8 --batch_size=32 --no_amp=false --max_steps=25000 --compile=false --save_interval=1000 --save_n_mins_before_timeout=5 --mean_recurrence_schedule.turn_on=true --mean_recurrence_schedule.warmup=0.25 --mean_recurrence_schedule.max_mean_rec=4 --muon.use_muon=true --muon.lr=0.001

## phase one of two phase
# tinyllama non-recurrent
python train.py --epochs=1 --max_length=1024 --out_path=huginn_llama --optim_config.lr=5e-5 --model_name="TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T" --preprocessed_data_path="$PROCESSED_DATA_PATH/smcleish/Recurrent-TinyLlama-3T-untrained/tinyllama_1_1b_packed_350b_sample_wrapped_packing/dataset" --is_parquet_dataset=true --scheduler_args.cooldown=0.9 --scheduler_args.warmup=0.005 --max_grad_norm=1.0 --micro_batch_size=8 --batch_size=32 --no_amp=false --max_steps=25000 --compile=false --non_recurrent_model=true --save_interval=1000 --save_n_mins_before_timeout=5 --muon.use_muon=true --muon.lr=0.001 --run_name=first_phase_non_rec

# tinyllama 4,8,4 init
python train.py --epochs=1 --max_length=1024 --out_path=huginn_llama --optim_config.lr=5e-5 --model_name="smcleish/Recurrent-TinyLlama-3T-untrained" --preprocessed_data_path="$PROCESSED_DATA_PATH/smcleish/Recurrent-TinyLlama-3T-untrained/tinyllama_1_1b_packed_350b_sample_wrapped_packing/dataset" --is_parquet_dataset=true --scheduler_args.cooldown=0.9 --scheduler_args.warmup=0.005 --max_grad_norm=1.0 --micro_batch_size=8 --batch_size=32 --no_amp=false --max_steps=25000 --compile=false --save_interval=1000 --save_n_mins_before_timeout=5 --mean_recurrence_schedule.turn_on=true --mean_recurrence_schedule.warmup=0.25 --muon.use_muon=true --muon.lr=0.001 --run_name=first_phase_4_8_4

## phase two of two phase
# tinyllama non-recurrent, starting from first_phase_non_rec
python train.py --epochs=1 --max_length=1024 --out_path=huginn_llama --optim_config.lr=5e-5 --model_name="huginn_llama/first_phase_non_rec/model_only_chkpt_25000" --preprocessed_data_path="$PROCESSED_DATA_PATH/smcleish/Recurrent-TinyLlama-3T-untrained/fineweb_nemotron_sft_general_math_even_mix/dataset" --is_parquet_dataset=true --scheduler_args.cooldown=0.9 --scheduler_args.warmup=0.005 --max_grad_norm=1.0 --micro_batch_size=8 --batch_size=32 --no_amp=false --max_steps=25000 --compile=false --non_recurrent_model=true --save_interval=1000 --save_n_mins_before_timeout=5 --muon.use_muon=true --muon.lr=0.001

# tinyllama 4,8,4 init, starting from first_phase_4_8_4
python train.py --epochs=1 --max_length=1024 --out_path=huginn_llama --optim_config.lr=5e-5 --model_name="huginn_llama/first_phase_4_8_4/model_only_chkpt_25000" --preprocessed_data_path="$PROCESSED_DATA_PATH/smcleish/Recurrent-TinyLlama-3T-untrained/fineweb_nemotron_sft_general_math_even_mix/dataset" --is_parquet_dataset=true --scheduler_args.cooldown=0.9 --scheduler_args.warmup=0.005 --max_grad_norm=1.0 --micro_batch_size=8 --batch_size=32 --no_amp=false --max_steps=25000 --compile=false --save_interval=1000 --save_n_mins_before_timeout=5 --mean_recurrence_schedule.turn_on=true --mean_recurrence_schedule.warmup=0.25 --mean_recurrence_schedule.max_mean_rec=4 --muon.use_muon=true --muon.lr=0.001